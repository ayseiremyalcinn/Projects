# -*- coding: utf-8 -*-
"""assignment_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y87ND0jZVIeIp5jivst8lc8Pq63Ylzc3
"""

import pandas as pd
pd.options.mode.chained_assignment = None
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from math import log

#with google colab
from google.colab import drive
drive.mount('/content/drive')

#read data with Pandas
df=pd.read_csv("/content/drive/MyDrive/Fall'22/BBM409/deneme/English Dataset.csv")

df

from sklearn.utils import shuffle
df = shuffle(df, random_state = 45)

df

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()
df["Category"] = le.fit_transform(df["Category"])

df["Category"]

X = df["Text"]
y = df["Category"]

class NaiveBayes:
    def __init__(self):
      self.prior_prob = []
      self.num_text = []
      self.Unigram_Bow = []
      self.Bigram_Bow = []
      self.categories = []

    def train(self, X_train, y_train, stop_words=[]):
      self.X_train = X_train
      self.y_train = y_train
      self.train=pd.concat([X_train, y_train], axis=1)
      self.Unigram_Bow = self.calculate_Bow(self.train,1,stop_words)
      self.Bigram_Bow = self.calculate_Bow(self.train,2,stop_words)
      
      self.prior_prob = [0 for i in range(len(self.num_text))]                  # calculate prior probabilities of categories 
      for i in range(len(self.num_text)): 
        self.prior_prob[i] = log(self.num_text[i]/sum(self.num_text))           # category count/ all categories

    def train_TF_IDF(self, X_train, y_train,stop_words=[]):
      self.X_train = X_train
      self.y_train = y_train
      self.train=pd.concat([X_train, y_train], axis=1)
      self.Unigram_Bow = self.tf_idf(self.train,1,stop_words)
      self.Bigram_Bow = self.tf_idf(self.train,2,stop_words)
      
      self.prior_prob = [0 for i in range(len(self.num_text))]                  # calculate prior probabilities of categories 
      for i in range(len(self.num_text)):
        self.prior_prob[i] = log(self.num_text[i]/sum(self.num_text))           # category count/ all categories

    
    
    def predict(self, X_test, n_gram):
        y_pred=[]
        for x in X_test:
            y_pred.append(self.make_predict(x, n_gram))
        return y_pred

    # Creates BoW using CountVectorizer
    def calculate_Bow(self, train, n_gram,stop_words):
      self.categories = train["Category"].unique()
      self.num_text = [0 for i in range(len(self.categories))]
      bow = ["" for i in range(len(self.categories))]                           

      for category in range(len(self.categories)):                              # BoW will be an array of all strings in the category when the loop is over
        df_bow=train[(train["Category"]==category)] 
        bow[category] = df_bow["Text"]
        self.num_text[category] += len(df_bow)

      for i in range(len(bow)):
        vectorizer = CountVectorizer(lowercase = True, ngram_range= (n_gram,n_gram),stop_words=stop_words)    # create Vectorizer object
        count_matrix = vectorizer.fit_transform(bow[i])
        count_array = count_matrix.toarray()        
        bow_df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())  
        bow[i] = bow_df.sum(axis=0).to_dict()                                   # create dictionary with words
        
      self.unique_texts = {}

      for d in [bow[0], bow[1], bow[2], bow[3], bow[4]]:
        self.unique_texts.update(d)                       # we will use at log calculations

      return bow
    
    def tf_idf(self, train, n_gram,stop_words):
      self.categories = train["Category"].unique()
      self.num_text = [0 for i in range(len(self.categories))]
      bow = ["" for i in range(len(self.categories))]
      for category in range(len(self.categories)):
        df_bow=train[(train["Category"]==category)]
        bow[category] = df_bow["Text"]
        self.num_text[category] += len(df_bow)

      for i in range(len(bow)):
        # Create a Vectorizer Object
        vectorizer = TfidfVectorizer(lowercase=True,ngram_range=(n_gram,n_gram),stop_words=stop_words) # create Vectorizer object
        count_matrix = vectorizer.fit_transform(bow[i])
        count_array = count_matrix.toarray()
        bow_df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())
        bow[i] = bow_df.sum(axis=0).to_dict()          # create dictionary with words

        

      self.unique_texts = {}
      for d in [bow[0], bow[1], bow[2], bow[3], bow[4]]:    # we will use at log calculations
        self.unique_texts.update(d)
      return bow


    def make_predict(self, x, n_gram):
      category_score = [1 for i in range(len(self.categories))]
      if n_gram == 2:
        words = x.split()
        words = list(map(' '.join, zip(words[:-1], words[1:])))
        BoW = self.Bigram_Bow
      else:
        words = x.split(" ")
        BoW = self.Unigram_Bow
      for word in words:
        for i in range(len(category_score)):
          if word in BoW[i].keys():
            category_score[i] += log((BoW[i][word] + 1) /( sum(BoW[i].values()) + len(self.unique_texts.keys())))
          else:
            category_score[i] += log(1 / (sum(BoW[i].values()) + len(self.unique_texts.keys())))

      for i in range(len(category_score)):
        category_score[i] += self.prior_prob[i]
      return np.argmax(category_score)

    def get_most_presence_n_words(self,ngram,nWord):
      for i in range(len(self.Unigram_Bow)):
        print(le.inverse_transform([i])[0],":")
        if(ngram==1):
          print(sorted(self.Unigram_Bow[i].items(), key=lambda item: item[1] , reverse=True)[:nWord])
        else:
          print(sorted(self.Bigram_Bow[i].items(), key=lambda item: item[1] , reverse=True)[:nWord])

    def get_most_absence_n_words(self,ngram,nWord):
      for i in range(len(self.Unigram_Bow)):
        print(le.inverse_transform([i])[0],":")
        if(ngram==1):
          print(sorted(self.Unigram_Bow[i].items(), key=lambda item: item[1])[:nWord])
        else:
          print(sorted(self.Bigram_Bow[i].items(), key=lambda item: item[1])[:nWord])

    def get_list_of_words(self,words):
      for i in range(len(self.Unigram_Bow)):
        print(le.inverse_transform([i])[0],":")
        for key in words:
          print(key,"->",self.Unigram_Bow[i][key],"   ",end="")
        print()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

"""# **Understanding Data**

*Here is some word with their occurence in all data can show as their categories.* 

We can see the occurrences of several words `"mr", "new", "year"`. If we want to make a comment, `"mr"` appears more in politics, that is, the word `"mr"` in political texts affects the classification. Since `"mr"` is used the least in sports, the word `"mr"` has little effect in sports text. For `"mr"` we can say that it is a word that has an effect on classification. However, the occurrences of the words `"new"` and `"year"` are almost the same for each category. We think that these words do not have a huge impact on categorization.
"""

clf = NaiveBayes()
clf.train(X, y)
clf.get_list_of_words(["mr","new","year"])

"""# A) **Analyzing effect of the words on prediction**

**List the 10 words whose presence most strongly predicts that the article belongs to specific category for each five categories.**

In below we see 10 words whose presence most strongly predicts in Unigram for all categories.

All of them have some common words in presence most strongly predicts 10 words. These are;
`"the","to","of","in","and","for"`. However all of these are stopwords. We will estimate without stopwords next part.
"""

clf = NaiveBayes()
clf.train_TF_IDF(X_train, y_train)
clf.get_most_presence_n_words(1,10)

"""In below we see 10 words whose presence most strongly predicts in Bigram for all categories.

All of them have some common words in absence most strongly predicts 10 words. These are;
`"of the","in the"`. However all of these are stopwords. We will estimate without stopwords next part. 

At **business** we can see `"the us","the company" `, at **entertainment** we can see `"the film"`, at politics we can see `"mr blair", "mr brown", "the government", "mr brown` in the most occurence 10 words. We know that this words related with their categories.
"""

clf.get_most_presence_n_words(2,10)

"""**List the 10 words whose absence most strongly predicts that the article belongs to specific category for each five categories.**

We can see that this words so unrelated with their categories. In **sport** we clearly see these words are absence because these words corresponding year. Presumably, when we try to predict a text, it is very unlikely that the new text will include these years.
"""

clf = NaiveBayes()
clf.train_TF_IDF(X_train, y_train)
clf.get_most_absence_n_words(1,10)

"""-------------------------------------------------------------------------------------------

We can see that this pairs are so unrelated. Like `"000 years" `, `"12 more" `, `"and 68"`.
"""

clf.get_most_absence_n_words(2,10)

"""# B) **Stop Words**"""

from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
english_stopwords=list(ENGLISH_STOP_WORDS)
english_stopwords.append('said')
print(english_stopwords)

"""**List the 10 words whose presence most strongly predicts that the article belongs to specific category for each five categories.** 

**Without stop words!!!**

In below we see the most presence 10 words without stop words in Unigram for all categories.

We see business, politics and tech categories includes `"mr"` and all of them includes `"new"`. These words like stop words' behaviour. The other words related with their categories.
"""

clf = NaiveBayes()
clf.train_TF_IDF(X_train, y_train,english_stopwords)
clf.get_most_presence_n_words(1,10)

"""In below we see the most presence 10 words without stop words in Bigram for all categories.

In here the words so correlated with their categories. (We think the special name `mr brown` or `mr ebbers` may be important name in their categories.)
"""

clf.get_most_presence_n_words(2,10)

"""-------------------------------------------------------------------------------------------

**List the 10 words whose absence most strongly predicts that the article belongs to specific category for each five categories.**

**Without stop words!!!**

We can see that this words so unrelated with their categories. We can give an example same as with stop words part. 

If we want to give another unrelated some words , these are the numbers such as `"118"`, `"925p"`, `"50pc"`.
"""

clf = NaiveBayes()
clf.train_TF_IDF(X_train, y_train,english_stopwords)
clf.get_most_absence_n_words(1,10)

"""Non-stop words absence most of pairs included numbers in all categories."""

clf.get_most_absence_n_words(2,10)

"""**Analyzing effect of the stopwords: Why might it make sense to remove stop words when interpreting the model? Why might it make sense to keep stop words?**

In unigram remove stop-words is so effective. Because most of text include stop-words for predict we mostly need unique words. 

However in bigram it can effect bad. Because if we want to give text with stop-word in bigram, the model can't recognize some pairs like "won best" because this pair give in model like -> "won the" and "the best".

# **Accuracy**

*With stop words*
"""

clf = NaiveBayes()
clf.train(X_train, y_train)
y_pred = clf.predict(X_test, 1)
accuracy = accuracy_score(y_test, y_pred)
print("Unigram accuracy:",accuracy)

y_pred = clf.predict(X_test, 2)
accuracy = accuracy_score(y_test, y_pred)
print("Bigram accuracy:",accuracy)

"""*With stop words TF-IDF*"""

clf = NaiveBayes()
clf.train_TF_IDF(X_train, y_train)
y_pred = clf.predict(X_test, 1)
accuracy = accuracy_score(y_test, y_pred)
print("TF-IDF unigram accuracy",accuracy)

y_pred = clf.predict(X_test, 2)
accuracy = accuracy_score(y_test, y_pred)
print("TF-IDF bigram accuracy",accuracy)

"""*No stop words*"""

clf = NaiveBayes()
clf.train(X_train, y_train,english_stopwords)
y_pred = clf.predict(X_test, 1)
accuracy = accuracy_score(y_test, y_pred)
print("Non-stopword unigram accuracy:",accuracy)

y_pred = clf.predict(X_test, 2)
accuracy = accuracy_score(y_test, y_pred)
print("Non-stopword bigram accuracy:",accuracy)

"""*No stop words TF-IDF*"""

clf = NaiveBayes()
clf.train_TF_IDF(X_train, y_train,english_stopwords)
y_pred = clf.predict(X_test, 1)
accuracy = accuracy_score(y_test, y_pred)
print("TF-IDF unigram accuracy",accuracy)

y_pred = clf.predict(X_test, 2)
accuracy = accuracy_score(y_test, y_pred)
print("TF-IDF bigram accuracy",accuracy)

"""**With Stop Words**

Unigram accuracy: 0.9194630872483222

Bigram accuracy: 0.9463087248322147

**With Stop Words and With tf-idf**

TF-IDF unigram accuracy 0.8322147651006712

TF-IDF bigram accuracy 0.8993288590604027

**Without Stop Words**

Non-stopword unigram accuracy: 0.959731543624161

Non-stopword bigram accuracy: 0.7516778523489933

**Without Stop Words and With tf-idf**

TF-IDF unigram accuracy 0.9463087248322147

TF-IDF bigram accuracy 0.9530201342281879


**1) The least accuracy :** 

***Non-stopword bigram accuracy: 0.7516778523489933***

We see that the least accuracy in without stopword bigram, if we try to examine it we see that;


entertainment :
('won best', 37), ('named best', 36)

politics :
('told bbc', 86)

sport :
('told bbc', 50), ('australian open', 48)

tech :
('told bbc', 54) ('news website', 47)

These are unrelated pairs.

Another reason is that we are not removing stopwords from the test data. This will be resolved if we remove the stopwords from the test data and send them.

**2) The best accuracy :**

***Non-stopword unigram accuracy: 0.959731543624161 and non-stopword TF-IDF bigram accuracy 0.9530201342281879***

Without stopwords we can reach most related words in unigram so the accuracy is highest. 


For non-stopword TF-IDF bigram accuracy;

**business :**

('chief executive'), ('economic growth'), ('mr ebbers'), ('deutsche boerse'), ('oil prices'), ('new york'), ('mr glazer'), ('stock market'), ('fourth quarter'), ('sri lanka')

**entertainment :**

('box office'), ('new york), ('vera drake'), ('los angeles'), ('million dollar'), ('dollar baby'), ('best actress')

**politics :**

('mr blair'), ('mr brown'), ('prime minister'), ('mr howard'), ('general election'), ('tony blair'), ('kilroy silk'), ('mr kennedy'), ('lib dems')

**sport :**

('champions league'), ('davis cup'), ('grand slam'), ('new zealand'), ('world cup'), ('cross country'), ('manchester united)

**tech :**

('mobile phone'), ('mobile phones'), ('anti virus'), ('high definition'), ('bbc news'), ('ask jeeves'), ('consumer electronics'), ('wi fi')


These words are very related and their ratios are usually close to each other when compared to the size of the ratios in the with stop word tf-idf. And they don't need any stopword in between pairs so we don't need to drop the stopwords in test texts.

***3) Why doesn't TF-IDF improve accuracy?***

We think that it cause of the tf-idf ratio. In this example ;

business :

[('the', 70.95764876462664), ('to', 32.817908709006126), ('of', 28.381825584034942), ('in', 28.341438544205033), ('and', 21.49897057026608), ('said', 12.296416780507798), ('it', 11.707978624765063), ('that', 11.550008739780894), ('is', 11.539364304631231), ('for', 11.346785316842237)]

"the" has very large ratio when we compare with "for". Then the more related words can't effective in predict. However without stopwords unigram the ratio more close each other;

business :

[('year', 7.885523855358925), ('mr', 7.524265899440198), ('sales', 6.604490735213493), ('growth', 6.482519702778017), ('economy', 6.30511773311268), ('oil', 5.857026406753185), ('bank', 5.82927728165229), ('market', 5.823054761944759), ('firm', 5.719463036419863), ('new', 5.558714949453762)]







"""





