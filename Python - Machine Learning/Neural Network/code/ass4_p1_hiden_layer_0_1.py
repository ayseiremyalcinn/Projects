# -*- coding: utf-8 -*-
"""ass4_p1_Hiden Layer 0-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NRaviF3sKoeZ37Yuu34_g5TsT2QQN-U6
"""

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from math import log
import zipfile
import os
from pathlib import Path
import keras.utils as image
from sklearn.utils import shuffle
import random
import warnings
from PIL import Image
from sklearn import metrics
from sklearn.metrics import classification_report
from matplotlib import cm
import matplotlib.pyplot as plt
random.seed(42)

#with google colab
from google.colab import drive
drive.mount('/content/drive')

train = "/content/drive/MyDrive/Fall'22/BBM409/ass-4/Vegetable Images/train"
test =  "/content/drive/MyDrive/Fall'22/BBM409/ass-4/Vegetable Images/test"
validation = "/content/drive/MyDrive/Fall'22/BBM409/ass-4/Vegetable Images/validation"

def image_pros(path):
  X_ = []
  Y_ = []
  p = Path(path)
  dirs = p.glob("*")

  counter=0
  for i in dirs:
    label=str(i).split("/")[-1]
    count=0
      
    for j in i.glob("*.jpg"):
      img = image.load_img(j, color_mode = "grayscale" ,target_size=(60,60))
      img_array = image.img_to_array(img)
      X_.append(img_array.flatten())
      Y_.append([0 for i in range(15)])
      Y_[-1][counter] = 1
      count +=1
    
    counter +=1
  return X_, Y_


X_train, Y_train = image_pros(train)
X_test, Y_test = image_pros(test)
X_val, Y_val = image_pros(validation)

import numpy as np
import matplotlib.pyplot as plt
X_train = np.array(X_train)
Y_train = np.array(Y_train)
X_test = np.array(X_test)
Y_test = np.array(Y_test)
X_val = np.array(X_val)
Y_val = np.array(Y_val)

#Shuffle our data
X_train, Y_train = shuffle(X_train, Y_train,random_state=42)

#Normalisation
X_train = X_train/255.0
X_test = X_test/255.0
X_val = X_val/255.0

class Neural_Network:

  def __init__(self, hiden_layers, node_sizes, LR, batch_size, activ_func, epoch):
    self.hiden_layers = hiden_layers
    self.node_sizes = node_sizes
    self.LR = LR
    self.batch_size = batch_size
    self.activ_func = activ_func
    self.activ_outputs=0
    self.epoch = epoch

    weight_matrices = []
    biases = []

    for i in range(hiden_layers + 1):
      weight_matrices.append(np.random.randn(node_sizes[i+1], node_sizes[i])*0.1)
      biases.append(np.zeros((node_sizes[i+1],1)))

    self.weight_matrices = weight_matrices
    self.biases = biases


  def train(self, X_train, Y_train, X_val, Y_val, early_stopping):
    
    for i in range(self.epoch): # Epoch

      j= 0
      while j + self.batch_size < len(X_train):
        
        self.forward(X_train[j:j+self.batch_size])
        self.backward(X_train[j:j+self.batch_size], Y_train[j:j+self.batch_size])
        j += self.batch_size

      
      Y_predict = self.forward(X_train)
      

      a_out=np.argmax(Y_predict,0)
      y_out=np.argmax(Y_train.T,0)
      acc=np.mean(y_out==a_out)*100
      train_cost = self.compute_loss(Y_train.T, Y_predict)  #cost
      

      Y_predict = self.forward(X_val)
      
      a_out=np.argmax(Y_predict,0)
      y_val_out=np.argmax(Y_val.T,0)
      acc2=np.mean(y_val_out==a_out)*100

      val_cost = self.compute_loss(Y_val.T, Y_predict)   # cost

      
      
      print("Epoch {}: training cost = {}, validation cost = {}".format(i+1 ,train_cost, val_cost))
      print("Train Accuracy:",acc,"Validation Accuracy:",acc2)

      if early_stopping and i % 5 == 0 and val_cost > train_cost:
        break
  
  def predict(self, X_test):
    return self.forward(X_test)
        

  def compute_loss(self, Y, Y_predict):
        
    m=Y.shape[1]
    cost=-(1/m)*np.sum(Y*np.log(Y_predict))

    cost=np.squeeze(cost)

    return cost

  def forward(self, x):
    activ_outputs = [[] for i in range(len(self.weight_matrices) + 1)]
    activ_outputs[0] = x.T

    for i in range(len(self.weight_matrices)):
      self.z = np.dot(self.weight_matrices[i], activ_outputs[i]) + self.biases[i]     
      activation_func = self.activ_func[i]
      activ_outputs[i+1] = eval("self." + activation_func + "()")

    self.activ_outputs=activ_outputs

    return activ_outputs[-1]

  def backward(self, x, y):

    m = x.shape[0]

    cache = self.weight_matrices
    cache_bias = self.biases

    delta = self.activ_outputs[-1] - y.T
    wn = (1/m) * np.dot(delta, self.activ_outputs[-2].T)
    bn = (1/m) * (np.sum(delta, axis=1,keepdims=True))


    cache[-1] -= self.LR * wn
    cache_bias[-1] -= self.LR * bn

    

    for i in range(len(self.weight_matrices)-1, 0, -1):
      self.out = self.activ_outputs[i]
      activ_func = self.activ_func[i-1]

      delta = np.dot(self.weight_matrices[i].T, delta) * eval("self.derivative_{}{}".format(activ_func, "()" ))
      wn = (1/m) *(np.dot(delta, self.activ_outputs[i-1].T))
      bn = (1/m) *(np.sum(delta, axis=1,keepdims=True))

      cache[i-1] -= self.LR * wn
      cache_bias[i-1] -= self.LR * bn

    self.weight_matrices = cache
    self.biases = cache_bias

  def relu(self):
    return np.maximum(0, self.z)


  def softmax(self):
    
    expZ = np.exp(self.z)
    return expZ/(np.sum(expZ, 0))

  def sigmoid(self):
    warnings.filterwarnings('ignore')
    return np.divide(1, np.add(1, np.exp(-self.z)))

  def tanh(self):
    # t=(np.exp(self.z)-np.exp(-self.z))/(np.exp(self.z)+np.exp(-self.z))
    # return t
    return np.tanh(self.z)

  def derivative_relu(self):

    y = np.zeros_like(self.out)
    y[self.out> 0] = 1

    return y

  def derivative_tanh(self):
    return (1 - np.power(self.out, 2))

  def derivative_sigmoid(self):
    return (1 - np.power(self.out, 2))

  def confusion_m(self, x, y):
    pred = self.predict(x)

    a_out=np.argmax(pred,0)
    y_out=np.argmax(y.T,0)

    acc=np.mean(y_out==a_out)*100

    confusion_matrix = metrics.confusion_matrix(y_out, a_out)

    print(classification_report(y_out, a_out, digits=3))
    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [
    'Bean',
    'Bitter_Gourd',
    'Bottle_Gourd',
    'Brinjal',
    'Broccoli',
    'Cabbage',
    'Capsicum',
    'Carrot',
    'Cauliflower',
    'Cucumber',
    'Papaya',
    'Potato',
    'Pumpkin',
    'Radish',
    'Tomato'])

    fig, ax = plt.subplots(figsize=(18,18))
    cm_display.plot(ax=ax) 
    plt.show()


  def visualize_weights(self,n):


    display_labels = [
        'Bean',
        'Bitter_Gourd',
        'Bottle_Gourd',
        'Brinjal',
        'Broccoli',
        'Cabbage',
        'Capsicum',
        'Carrot',
        'Cauliflower',
        'Cucumber',
        'Papaya',
        'Potato',
        'Pumpkin',
        'Radish',
        'Tomato']
    counter = 0
    for i in self.weight_matrices[-1]:
      array =  i.reshape(n,n)
      array -= array.min()
      array *= 255.0/ array.max()
    
      im = Image.fromarray(array)
      plt.figure(figsize = (5,5))
      print(display_labels[counter])
      counter +=1
      plt.imshow(im)
      plt.show()

  def save_mode(self):
    np.save("weight_matrix", self.weight_matrices[-1])


# Zero Hiden Layer


model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.005, batch_size = 16, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.005, batch_size = 32, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.005, batch_size = 64, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.005, batch_size = 128, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.01, batch_size = 16, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.01, batch_size = 32, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.01, batch_size = 64, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.01, batch_size = 128, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.02, batch_size = 16, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.02, batch_size = 32, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.02, batch_size = 64, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.02, batch_size = 128, activ_func = ["softmax"] , epoch =30)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)

"""# One hiden layer"""

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 16, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 16, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 16, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 32, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 32, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 32, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 64, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 64, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 64, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 128, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 128, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.005, batch_size = 128, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 16, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 16, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 16, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 32, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 32, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 32, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 64, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 64, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 64, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 128, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 128, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.01, batch_size = 128, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 16, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 16, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 16, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 32, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 32, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 32, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 64, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 64, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 64, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 128, activ_func = ["sigmoid", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 128, activ_func = ["relu", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

model = Neural_Network(hiden_layers = 1, node_sizes = [3600, 1024, 15], LR = 0.02, batch_size = 128, activ_func = ["tanh", "softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = False)

model.confusion_m(X_test, Y_test)

model.visualize_weights(32)

"""# Test With Early Stopping"""

model = Neural_Network(hiden_layers = 0, node_sizes = [3600, 15], LR = 0.02, batch_size = 128, activ_func = ["softmax"] , epoch =15)
model.train(X_train= X_train,Y_train = Y_train, X_val = X_val, Y_val =Y_val, early_stopping = True)

model.confusion_m(X_test, Y_test)

model.visualize_weights(60)