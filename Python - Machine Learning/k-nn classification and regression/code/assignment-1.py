# -*- coding: utf-8 -*-
"""assignment-1_V2.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-DTPmV6NipC3cTHSszAz6I0eBzAhPl3U
"""

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

accuracy_df = pd.DataFrame()
precision_df = pd.DataFrame()
recall_df = pd.DataFrame()
allMetrics = []
misclassified_samples=[]
only_one=0

MAE1_df = pd.DataFrame()
MAE2_df = pd.DataFrame()
allMAE = []

"""# ***K-NN CLASSIFICATION PART***

>  # **k-nn classification without feature normalization**
"""

#read classification data with Pandas
df=pd.read_csv("/content/drive/MyDrive/Fall'22/bbm409/ass-1/subset_16P.csv", encoding='cp1252')

display(df)

#drop Response Id column because it was not important for train and test
df.drop(columns=["Response Id"],inplace=True)

#Shuffle DataFrame rows
import random
dfx=df.to_numpy()
dfx=sorted(dfx, key = lambda x: random.random())
dfy=pd.DataFrame(dfx)
df = dfy
display(df)

#get X data
X=df.iloc[:,:-1]

#get y data, its order is important
y=df.iloc[:,-1]

#Numeric expression is good for y variables
def label_encoding(y):
    unique=y.unique()
    labels={}
    count=0
    for i in unique:
        labels[i]=count
        count+=1
    column=y.name
    y_new=y.replace(labels)
    
    return (y_new,labels)

y_new,labels=label_encoding(y)

#you can see corresponding numeric expression for unique y variables
labels

#here is k_nn classification algorithm class
class k_nn_classification:
    #initialize with k
    def __init__(self,k):
        self.k = k
    #fit model is simple because we only kept X_train and y_train in memory
    def fit(self,X_train,y_train):
        self.X_train=X_train
        self.y_train=y_train

    def classification(self,y_test,y_predict,class_list):
      global only_one
      global misclassified_samples
      size=len(y_predict)
      confusion_matrix={}
      metrices={}
      #create an empty confusion matrix with dictionary
      for i in range(len(class_list)):
          confusion_matrix[i]={"TP":0,"TN":0,"FP":0,"FN":0}
          metrices[i]={"acc":0,"pre":0,"rec":0}
      #fill confusion matrix
      for true,pred in zip(y_test,y_predict):
          if(true==pred):
              #when true==pred it is TP for true class
              confusion_matrix[true]["TP"]+=1
          else:
              #when true!=pred it is FN for true class, FP for pred class 
              confusion_matrix[true]["FN"]+=1
              confusion_matrix[pred]["FP"]+=1
              if(only_one==0):
                misclassified_samples.append([true,pred])
      only_one+=1

      for i in confusion_matrix.keys():
          #the remining predic for each class is TN it means the predict or the true is not equal to i. class
          confusion_matrix[i]["TN"]=size-sum(confusion_matrix[i].values())
      
      
      for k in confusion_matrix.keys():
        #use "try-except" for prevent from zero division. If any of this cause zero division, its variable will be 0.
        try:
          metrices[k]["acc"]=(confusion_matrix[k]["TP"]+confusion_matrix[k]["TN"])/(confusion_matrix[k]["TP"]+confusion_matrix[k]["TN"]+confusion_matrix[k]["FP"]+confusion_matrix[k]["FN"])
        except:
          print("zero division in accuracy")

        try:
          metrices[k]["pre"]=confusion_matrix[k]["TP"]/(confusion_matrix[k]["TP"]+confusion_matrix[k]["FP"])
        except:
          print("zero division in precision")
        
        try:
          metrices[k]["rec"]=confusion_matrix[k]["TP"]/(confusion_matrix[k]["TP"]+confusion_matrix[k]["FN"])
        except:
          print("zero division in recall")

         # this function returns all metrices with average
      return metrices
    
        
    def euclidean_distance(self,X_train,X_test):
            #compute euclidean distance with every training data(all training data) and each test data(only one test data)
            X_train=X_train.to_numpy()
            X_test=np.asarray(X_test)


            #return all distances between all training data and one test data
            return np.sqrt(np.sum(np.square(np.abs(X_train-X_test)),axis=1))
        
    def predict(self,X_test):
        y_predict=[]
        for i in range(X_test.shape[0]):
            #calculate all distances
            distance=self.euclidean_distance(self.X_train,list(X_test.iloc[i,:]))
            #concate them with corresponding y train
            concate=sorted(list(zip(distance,self.y_train)))
            #take first k distances and y trains
            classes=concate[:self.k]

            #count all first k "y_train"
            alls={}
            for i in classes:
                try:
                    alls[i[1]]+=1
                except:
                    alls[i[1]]=1
            #predict y for X test
            y_pred=None
            max_number=0
            for k,v in alls.items():
                if(v>max_number):
                    max_number=v
                    y_pred=k
            y_predict.append(y_pred)
        return y_predict

def cross_val_score_classification(clf, X, y, cv,class_list):
        
        #split n-folds all data
        folds = np.array_split(pd.concat([X, y], axis=1), cv)

        metrics=[]
        for i in range(cv):
            #iterate n times the train-test for each fold
            train = folds.copy()
            test = folds[i]
            del train[i]
            train = pd.concat(train, sort=False)

            X_train=train.iloc[:,:-1]
            y_train=train.iloc[:,-1]
            
            X_test=test.iloc[:,:-1]
            y_test=test.iloc[:,-1]
            
            #fit model to given classification algorithm
            clf.fit(X_train, y_train)
            #predict values
            y_predict=clf.predict(X_test)
            #evaluate predict values
            metrices=clf.classification(y_test,y_predict,class_list)
            #append metrices a list because we will predict n times
            metrics.append(metrices)
        accuracy={}
        precision={}
        recall={}
        count=1
        for i in range(len(class_list)):
          accuracy[i]={}
          precision[i]={}
          recall[i]={}
          for j in range(cv):
              accuracy[i]["FOLD-{}".format(j+1)]=0
              precision[i]["FOLD-{}".format(j+1)]=0
              recall[i]["FOLD-{}".format(j+1)]=0

        for i in metrics:
          for j in range(len(class_list)):
            accuracy[j]["FOLD-{}".format(count)]=i[j]["acc"]
            precision[j]["FOLD-{}".format(count)]=i[j]["pre"]
            recall[j]["FOLD-{}".format(count)]=i[j]["rec"]
          count+=1
          
        return (accuracy,precision,recall)

from IPython.display import display
def evaluation(metrics,class_names):
    global accuracy_df  
    global precision_df 
    global recall_df

    titles=["Accuracy","Precision","Recall"]
    for i,j in zip(metrics,titles):

      df=pd.DataFrame(i)
      df.columns=class_names
      new_df=pd.DataFrame(df.mean(axis=1)).T

      if(j == "Accuracy"):
        accuracy_df = pd.concat([accuracy_df, new_df.T], axis=1)
      if(j == "Precision"):
        precision_df = pd.concat([precision_df, new_df.T], axis=1)
      if(j == "Recall"):
        recall_df = pd.concat([recall_df, new_df.T], axis=1)

"""**Here is k=[1,3,5,7,9] k-nn algorithm evaluation:**"""

clf1=k_nn_classification(1)
metrics1=cross_val_score_classification(clf1, X, y_new, 5,y.unique())
allMetrics.append(metrics1)

clf2=k_nn_classification(3)
metrics2=cross_val_score_classification(clf2, X, y_new, 5,y.unique())
allMetrics.append(metrics2)

clf3=k_nn_classification(5)
metrics3=cross_val_score_classification(clf3, X, y_new, 5,y.unique())
allMetrics.append(metrics3)

clf4=k_nn_classification(7)
metrics4=cross_val_score_classification(clf4, X, y_new, 5,y.unique())
allMetrics.append(metrics4)

clf5=k_nn_classification(9)
metrics5=cross_val_score_classification(clf5, X, y_new, 5,y.unique())
allMetrics.append(metrics5)

"""#> **weighted k-nn without feature normalization**"""

#here is weighted k_nn classification algorithm class
class weighted_k_nn_classification:
    #initialize with k
    def __init__(self,k):
        self.k = k
    #fit model is simple because we only kept X_train and y_train in memory    
    def fit(self,X_train,y_train):
        self.X_train=X_train
        self.y_train=y_train
        
    def classification(self,y_test,y_predict,class_list):
      global only_one
      global misclassified_samples

      size=len(y_predict)
      confusion_matrix={}
      metrices={}
      #create an empty confusion matrix with dictionary
      for i in range(len(class_list)):
          confusion_matrix[i]={"TP":0,"TN":0,"FP":0,"FN":0}
          metrices[i]={"acc":0,"pre":0,"rec":0}
      #fill confusion matrix
      for true,pred in zip(y_test,y_predict):
          if(true==pred):
              #when true==pred it is TP for true class
              confusion_matrix[true]["TP"]+=1
          else:
              #when true!=pred it is FN for true class, FP for pred class
              confusion_matrix[true]["FN"]+=1
              confusion_matrix[pred]["FP"]+=1
              if(only_one==0):
                misclassified_samples.append([true,pred])
      only_one+=1

      for k in confusion_matrix.keys():
          #the remining predict for each class is TN it means the predict or the true is not equal to i. class
          
          confusion_matrix[k]["TN"]=size-sum(confusion_matrix[k].values())
      
      
      for k in confusion_matrix.keys():
        #use "try-except" for prevent from zero division. If any of this cause zero division, its variable will be 0.
        try:
          metrices[k]["acc"]=(confusion_matrix[k]["TP"]+confusion_matrix[k]["TN"])/(confusion_matrix[k]["TP"]+confusion_matrix[k]["TN"]+confusion_matrix[k]["FP"]+confusion_matrix[k]["FN"])
        except:
          print("zero division in accuracy")

        try:
          metrices[k]["pre"]=confusion_matrix[k]["TP"]/(confusion_matrix[k]["TP"]+confusion_matrix[k]["FP"])
        except:
          print("zero division in precision")
        
        try:
          metrices[k]["rec"]=confusion_matrix[k]["TP"]/(confusion_matrix[k]["TP"]+confusion_matrix[k]["FN"])
        except:
          print("zero division in recall")
      # this function returns all metrices
      return metrices

    def euclidean_distance(self,X_train,X_test):
            #compute euclidean distance with every training data(all training data) and each test data(only one test data)
            X_train=X_train.to_numpy()
            X_test=np.asarray(X_test)
            #return all distances between all training data and one test data
            return np.sqrt(np.sum(np.square(np.abs(X_train-X_test)),axis=1))

    def predict(self,X_test):
        y_predict=[]
        for i in range(X_test.shape[0]):
            #calculate all distances
            distance=self.euclidean_distance(self.X_train,list(X_test.iloc[i,:]))
            # inversely proportion gives weighted distance
            distance=1/distance
            #concate them with corresponding y train
            concate=sorted(list(zip(distance,self.y_train)),reverse=True)
            #take first k distances and y trains
            classes=concate[:self.k]
            #calculate sum of weighted
            alls={}
            for i in classes:
                try:
                    alls[i[1]]+=i[0]
                except:
                    alls[i[1]]=i[0]
            #predict y for X test
            y_pred=None
            max_number=0
            for k,v in alls.items():
                if(v>max_number):
                    max_number=v
                    y_pred=k
            y_predict.append(y_pred)

        return y_predict

clf_w1=weighted_k_nn_classification(1)
metric=cross_val_score_classification(clf_w1, X, y_new, 5,y.unique())
allMetrics.append(metric)

clf_w2=weighted_k_nn_classification(3)
metric=cross_val_score_classification(clf_w2, X, y_new, 5,y.unique())
allMetrics.append(metric)

clf_w3=weighted_k_nn_classification(5)
metric=cross_val_score_classification(clf_w3, X, y_new, 5,y.unique())
allMetrics.append(metric)

clf_w4=weighted_k_nn_classification(7)
metric=cross_val_score_classification(clf_w4, X, y_new, 5,y.unique())
allMetrics.append(metric)

clf_w5=weighted_k_nn_classification(9)
metric=cross_val_score_classification(clf_w5, X, y_new, 5,y.unique())
allMetrics.append(metric)

""" >  # **k-nn classification with feature normalization**"""

def min_max_normalization(df):

    df= (df-df.min())/(df.max()-df.min())
    
    return df

X_norm=min_max_normalization(X)
X_norm

clf1_norm=k_nn_classification(1)
metric=cross_val_score_classification(clf1_norm, X_norm, y_new, 5,y.unique())
allMetrics.append(metric)

clf2_norm=k_nn_classification(3)
metric=cross_val_score_classification(clf2_norm, X_norm, y_new, 5,y.unique())
allMetrics.append(metric)

clf3_norm=k_nn_classification(5)
metric=cross_val_score_classification(clf3_norm, X_norm, y_new, 5,y.unique())
allMetrics.append(metric)

clf4_norm=k_nn_classification(7)
metric=cross_val_score_classification(clf4_norm, X_norm, y_new, 5,y.unique())
allMetrics.append(metric)

clf5_norm=k_nn_classification(9)
metric=cross_val_score_classification(clf5_norm, X_norm, y_new, 5,y.unique())
allMetrics.append(metric)

"""#> **weighted k-nn with feature normalization**"""

clf_w1_norm=weighted_k_nn_classification(1)
metric=cross_val_score_classification(clf_w1_norm, X, y_new, 5,y.unique())
allMetrics.append(metric)

clf_w2_norm=weighted_k_nn_classification(3)
metric=cross_val_score_classification(clf_w2_norm, X, y_new, 5,y.unique())
allMetrics.append(metric)

clf_w3_norm=weighted_k_nn_classification(5)
metric=cross_val_score_classification(clf_w3_norm, X, y_new, 5,y.unique())
allMetrics.append(metric)

clf_w4_norm=weighted_k_nn_classification(7)
metric=cross_val_score_classification(clf_w4_norm, X, y_new, 5,y.unique())
allMetrics.append(metric)

clf_w5_norm=weighted_k_nn_classification(9)
metric=cross_val_score_classification(clf_w5_norm, X, y_new, 5,y.unique())
allMetrics.append(metric)

"""# ERROR ANAYLSIS FOR CLASSIFICATION

**-Missed classification analysis**

We wanted to deal with the misclassifications of 4 different situations. These are k-nn k=3,k=5 and weighted k-nn k=3, k=5. We have 33 misclassifieds for k-nn k=3. Of these, 15 is the most misclassified. Probably their X values ​​are located far from their class.  These can vary according to the values ​​of k and the distance of X to its own class. When k=5, these errors are reduced.

When we look at Weighted k-nn k=3, the errors have increased. This may be related to the misclassified value being close to other classes at k=3. And this is also related to the decrease and increase of k. It is seen that less error is taken at k=5.

Also, since our test size is 2 thousand, these errors are not very troublesome. Because it is possible in real life problems that some X values ​​may remain outlier.
"""

only_one=0
misclassified_samples=[]
clf_error=k_nn_classification(3)
cross_val_score_classification(clf_error, X, y_new, 5,y.unique())
count_misses={}
for i in misclassified_samples:
  print("True Value:",i[0],"Predict Value:",i[1])
  try:
    count_misses[i[0]]+=1
  except:
    count_misses[i[0]]=1
print("Misses counts:")
print(count_misses)
print("Total misses:",sum(count_misses.values()))

only_one=0
misclassified_samples=[]
clf_error2=k_nn_classification(5)
metric=cross_val_score_classification(clf_error2, X, y_new, 5,y.unique())
count_misses={}
for i in misclassified_samples:
  print("True Value:",i[0],"Predict Value:",i[1])
  try:
    count_misses[i[0]]+=1
  except:
    count_misses[i[0]]=1
print("Misses counts:")
print(count_misses)
print("Total misses:",sum(count_misses.values()))

only_one=0
misclassified_samples=[]
clf_error3=weighted_k_nn_classification(3)
metric=cross_val_score_classification(clf_error3, X, y_new, 5,y.unique())
count_misses={}
for i in misclassified_samples:
  print("True Value:",i[0],"Predict Value:",i[1])
  try:
    count_misses[i[0]]+=1
  except:
    count_misses[i[0]]=1
print("Misses counts:")
print(count_misses)
print("Total misses:",sum(count_misses.values()))

only_one=0
misclassified_samples=[]
clf_error4=weighted_k_nn_classification(5)
metric=cross_val_score_classification(clf_error4, X, y_new, 5,y.unique())
count_misses={}
for i in misclassified_samples:
  print("True Value:",i[0],"Predict Value:",i[1])
  try:
    count_misses[i[0]]+=1
  except:
    count_misses[i[0]]=1
print("Misses counts:")
print(count_misses)
print("Total misses:",sum(count_misses.values()))

"""**-Classification Metrics**"""

for i in allMetrics:
  evaluation(i,y.unique())

column = ["knn-1", "knn-3","knn-5","knn-7","knn-9","W-knn-1","W-knn-3","W-knn-5","W-knn-7","W-knn-9","FN-knn-1","FN-knn-3","FN-knn-5","FN-knn-7","FN-knn-9","FN-W-knn-1","FN-W-knn-3","FN-W-knn-5","FN-W-knn-7","FN-W-knn-9"]

accuracy_df.columns = column
precision_df.columns = column
recall_df.columns = column

avgAcc = pd.DataFrame(accuracy_df.mean(axis=0)).T
avgAcc.rename(index={0: "Average Accuracy"}, inplace = True)
avgPre = pd.DataFrame(precision_df.mean(axis=0)).T
avgPre.rename(index={0: "Average Precision"}, inplace = True)
avgRec = pd.DataFrame(recall_df.mean(axis=0)).T
avgRec.rename(index={0: "Average Recall"}, inplace = True)
print("ACCURACY TABLE")
display(accuracy_df)
display(avgAcc)
print()
print("PRECISION TABLE")
display(precision_df)
display(avgPre)
print()
print("RECALL TABLE")
display(recall_df)
display(avgRec)
print()

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
figure(figsize=(24, 6), dpi=80)

plt.title('Average Accuracy Table')
plt.plot(column, avgAcc.loc['Average Accuracy'], label = 'Testing Accuracy')
plt.legend()
plt.show()
figure(figsize=(24, 6), dpi=80)
plt.title('Average Precision Table')
plt.plot(column, avgPre.loc['Average Precision'], label = 'Testing Precision')
plt.legend()
plt.show()
figure(figsize=(24, 6), dpi=80)
plt.title('Average Recall Table')
plt.plot(column, avgRec.loc['Average Recall'], label = 'Testing Recall')
plt.legend()
plt.show()

"""According to Classification Performance Metrics, all algorithms work with a success rate of over 99%. Due to the sensitivity of the results, there may be unreasonable deviations in the graph. 

Computation time complexity of the algorithm is:

***O(Fold size * test size * (train size * Log(train size)))***

The total computation time of 20 algorithms is 30 minutes.




>**The effect of k:** 
As the number k increases, the probability of error decreases. However, as the k number increases, overfitting may occur. The number k is the number of neighbors to be included in the calculation. The number of neighbors included in the calculation should be chosen optimally. The elbow points on the Accuracy graph are the optimum k values.



> **The effect of the number of training samples used:** 
If the number of samples were increased, the measurement time would increase, but the error rate would decrease. We use all data as train data using cross validation.



> **The effect of using weighted k-NN:**
The intuition behind weighted kNN, is to give more weight to the points which are nearby and less weight to the points which are farther away. The simple function which is used is the inverse distance function. Thus, more accurate data were obtained. However, since our results have an accuracy of over 99%, its effect cannot be observed.



> **The effect of min-max normalization:**
There is less misclassification when classification is made on the normalized data. Because normalization helps reduce misclassification by scaling the data when unrelated product data are collected in the same table. It is prevented that the results are affected by too large and too small attributes. The effect of normalization is not great because the attributes are close values in the sample data.

# ***K-NN REGRESSION PART***

>  # **k-nn regression without feature normalization**
"""

df2=pd.read_csv("/content/drive/MyDrive/Fall'22/bbm409/ass-1/energy_efficiency_data.csv")

df2.head()

#Shuffle DataFrame rows
import random
dfx=df2.to_numpy()
dfx=sorted(dfx, key = lambda x: random.random())
dfy=pd.DataFrame(dfx)
df2 = dfy
display(df2)

X=df2.iloc[:,:-2]

y=df2.iloc[:,-2:]

#here is k_nn regression algorithm class
class k_nn_regression:
    #initialize with k
    def __init__(self,k):
        self.k = k
     #fit model is simple because we only kept X_train and y_train in memory
    def fit(self,X_train,y_train):
        self.X_train=X_train
        self.y_train=y_train
    #calculate Mean Absolute Error
    def MAE(self,y_test,y_pred):
      y_test=y_test.to_numpy()
      y_pred=np.asarray(y_pred)

      return np.sum(np.abs(y_test-y_pred),axis=0)/len(y_test)
    
        
    def euclidean_distance(self,X_train,X_test):
      #compute euclidean distance with every training data(all training data) and each test data(only one test data)
            X_train=X_train.to_numpy()
            X_test=np.asarray(X_test)
            #return all distances between all training data and one test data
            return np.sqrt(np.sum(np.square(np.abs(X_train-X_test)),axis=1))
        
    def predict(self,X_test):
        y_predict=[]
        for i in range(X_test.shape[0]):
            #calculate all distances
            distance=self.euclidean_distance(self.X_train,list(X_test.iloc[i,:]))
            #concate them with corresponding y train
            train_y=self.y_train.to_numpy()
            concate=np.concatenate((distance[:, None],train_y), axis=1)
            concate=sorted(concate.tolist())
            #take first k distances and y trains
            classes=concate[:self.k]
            y_pred=[0,0]
            #Predict with average of k values
            for i in classes:
                y_pred[0]+=i[1]
                y_pred[1]+=i[2]
            y_pred[0]/=self.k
            y_pred[1]/=self.k
            y_predict.append(y_pred)
        return y_predict

def cross_val_score_regression(reg, X, y, cv):
        #split n-folds all data
        folds = np.array_split(pd.concat([X, y], axis=1), cv)

        metrics=[]
        for i in range(cv):
            #iterate n times the train-test for each fold
            train = folds.copy()
            test = folds[i]
            del train[i]
            train = pd.concat(train, sort=False)

            X_train=train.iloc[:,:-2]
            y_train=train.iloc[:,-2:]
            
            X_test=test.iloc[:,:-2]
            y_test=test.iloc[:,-2:]
            #fit model to given regression algorithm
            reg.fit(X_train, y_train)
            #predict values
            y_predict=reg.predict(X_test)
            #evaluate predict values
            metrices=reg.MAE(y_test,y_predict)
            #append metrices a list because we will predict n times
            metrics.append(metrices)
        
        all_MAE={}
        for i in range(cv):
          all_MAE["FOLD-{}".format(i+1)]={}
          all_MAE["FOLD-{}".format(i+1)]["MAE"]=metrics[i]

        return all_MAE

reg1=k_nn_regression(1)
metrics=cross_val_score_regression(reg1, X, y, 5)
allMAE.append(metrics)

reg2=k_nn_regression(3)
metrics=cross_val_score_regression(reg2, X, y, 5)
allMAE.append(metrics)

reg3=k_nn_regression(5)
metrics=cross_val_score_regression(reg3, X, y, 5)
allMAE.append(metrics)

reg4=k_nn_regression(7)
metrics=cross_val_score_regression(reg4, X, y, 5)
allMAE.append(metrics)

reg5=k_nn_regression(9)
metrics=cross_val_score_regression(reg5, X, y, 5)
allMAE.append(metrics)

"""# **weighted k-nn regression without feature normalization**"""

#here is weighted k_nn regression algorithm class
class weighted_k_nn_regression:
  #initialize with k
    def __init__(self,k):
        self.k = k
     #fit model is simple because we only kept X_train and y_train in memory    
    def fit(self,X_train,y_train):
        self.X_train=X_train
        self.y_train=y_train
    #calculate Mean Absolute Error
    def MAE(self,y_test,y_pred):
      y_test=y_test.to_numpy()
      y_pred=np.asarray(y_pred)

      return np.sum(np.abs(y_test-y_pred),axis=0)/len(y_test)
    
    
    def euclidean_distance(self,X_train,X_test):
            #compute euclidean distance with every training data(all training data) and each test data(only one test data)
            X_train=X_train.to_numpy()
            X_test=np.asarray(X_test)
            #return all distances between all training data and one test data
            return np.sqrt(np.sum(np.square(np.abs(X_train-X_test)),axis=1))
        
    def predict(self,X_test):
        y_predict=[]
        for i in range(X_test.shape[0]):
             #calculate all distances
            distance=self.euclidean_distance(self.X_train,list(X_test.iloc[i,:]))
            # inversely proportion gives weighted distance
            distance=1/distance
            #concate them with corresponding y train
            train_y=self.y_train.to_numpy()
            concate=np.concatenate((distance[:, None],train_y), axis=1)
            concate=sorted(concate.tolist(),reverse=True)
            #take first k distances and y trains
            classes=concate[:self.k]
            y_pred=[0,0]
            weighted_total=0
            #Predict with average of weighted*k values
            for i in classes:
                y_pred[0]+=(i[1]*i[0])
                y_pred[1]+=(i[2]*i[0])
                weighted_total+=i[0]
            y_pred[0]/=weighted_total
            y_pred[1]/=weighted_total
            y_predict.append(y_pred)
        return y_predict

reg_w1=weighted_k_nn_regression(1)
metrics=cross_val_score_regression(reg_w1, X, y, 5)
allMAE.append(metrics)

reg_w2=weighted_k_nn_regression(3)
metrics=cross_val_score_regression(reg_w2, X, y, 5)
allMAE.append(metrics)

reg_w3=weighted_k_nn_regression(5)
metrics=cross_val_score_regression(reg_w3, X, y, 5)
allMAE.append(metrics)

reg_w4=weighted_k_nn_regression(7)
metrics=cross_val_score_regression(reg_w4, X, y, 5)
allMAE.append(metrics)

reg_w5=weighted_k_nn_regression(9)
metrics=cross_val_score_regression(reg_w5, X, y, 5)
allMAE.append(metrics)

"""# **k-nn regression with feature normalization**



"""

def min_max_normalization(df):

    df= (df-df.min())/(df.max()-df.min())
    
    return df

X_norm=min_max_normalization(X)
display(X_norm)

reg_norm1=k_nn_regression(1)
metrics=cross_val_score_regression(reg_norm1, X_norm, y, 5)
allMAE.append(metrics)

reg_norm2=k_nn_regression(3)
metrics=cross_val_score_regression(reg_norm2, X_norm, y, 5)
allMAE.append(metrics)

reg_norm3=k_nn_regression(5)
metrics=cross_val_score_regression(reg_norm3, X_norm, y, 5)
allMAE.append(metrics)

reg_norm4=k_nn_regression(7)
metrics=cross_val_score_regression(reg_norm4, X_norm, y, 5)
allMAE.append(metrics)

reg_norm5=k_nn_regression(9)
metrics=cross_val_score_regression(reg_norm5, X_norm, y, 5)
allMAE.append(metrics)

"""# **weighted k-nn regression with feature normalization**"""

reg_norm_w1=weighted_k_nn_regression(1)
metrics=cross_val_score_regression(reg_norm_w1, X_norm, y, 5)
allMAE.append(metrics)

reg_norm_w2=weighted_k_nn_regression(3)
metrics=cross_val_score_regression(reg_norm_w2, X_norm, y, 5)
allMAE.append(metrics)

reg_norm_w3=weighted_k_nn_regression(5)
metrics=cross_val_score_regression(reg_norm_w3, X_norm, y, 5)
allMAE.append(metrics)

reg_norm_w4=weighted_k_nn_regression(7)
metrics=cross_val_score_regression(reg_norm_w4, X_norm, y, 5)
allMAE.append(metrics)

reg_norm_w5=weighted_k_nn_regression(9)
metrics=cross_val_score_regression(reg_norm_w5, X_norm, y, 5)
allMAE.append(metrics)

"""# ERROR ANALYSIS FOR REGRESSION"""

column = ["knn-1", "knn-3","knn-5","knn-7","knn-9","W-knn-1","W-knn-3","W-knn-5","W-knn-7","W-knn-9","FN-knn-1","FN-knn-3","FN-knn-5","FN-knn-7","FN-knn-9","FN-W-knn-1","FN-W-knn-3","FN-W-knn-5","FN-W-knn-7","FN-W-knn-9"]

for metrics in allMAE:
  dfm = pd.DataFrame(metrics)
  dfm = pd.DataFrame(dfm.T['MAE'].to_list(), columns=['MAE1','MAE2'])

  MAE1_df = pd.concat([MAE1_df, dfm.loc[:, ['MAE1']]], axis=1)
  MAE2_df = pd.concat([MAE2_df, dfm.loc[:, ['MAE2']]], axis=1)
MAE1_df.columns = column
MAE2_df.columns = column

print("Heating Load MAE")
display(MAE1_df)
avgMAE1 = pd.DataFrame(MAE1_df.mean(axis=0)).T
avgMAE1.rename(index={0: "Average Heating Load"}, inplace = True)
print()
display(avgMAE1)
avgMAE2 = pd.DataFrame(MAE2_df.mean(axis=0)).T
avgMAE2.rename(index={0: "Average Cooling Load"}, inplace = True)
print("Cooling Load MAE")
display(MAE2_df)
print()
display(avgMAE2)

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
figure(figsize=(24, 6), dpi=80)

plt.title('Average Heating Load Table')
plt.plot(column, avgMAE1.loc['Average Heating Load'], label = 'Mean Absolute Error')
plt.legend()
plt.show()
print()
figure(figsize=(24, 6), dpi=80)
plt.title('Average Cooling Load Table')
plt.plot(column, avgMAE2.loc['Average Cooling Load'], label = 'Mean Absolute Error')
plt.legend()
plt.show()

"""
**According to Regression Performance Metric, Heating Load prediction work with a Mean Absolute Error between 1.6 and 3.2 . Cooling Load prediction work with a Mean Absolute Error between 1.5 and 3.5 .**

Computation time complexity of the algorithm is:

***O(Fold size * test size * (train size * Log(train size)))***


>**The effect of k:** 
As the number k increases, the probability of error decreases. however, as the k number increases, overfitting may occur. The number k is the number of neighbors to be included in the calculation. The number of neighbors included in the calculation should be chosen optimally. The elbow points on the Mean Absolute Error graphs are the optimum k values. It seems clear that Mean Absolute Error is optimum for k=5.



> **The effect of the number of training samples used:** 
If the number of samples were increased, the measurement time would increase, but the mean absolute error would decrease. We use all data as train data using cross validation. 



> **The effect of using weighted k-NN:**
The intuition behind weighted kNN, is to give more weight to the points which are nearby and less weight to the points which are farther away. The simple function which is used is the inverse distance function.Thus, more accurate data were obtained. 


> **The effect of min-max normalization:**
If the scale of features is very different then normalization is required. This is because the distance calculation done in KNN uses feature values. When the one feature values are large than other, that feature will dominate the distance hence the outcome of the KNN. Because normalization helps reduce error rate by scaling the data when unrelated product data are collected in the same table."""